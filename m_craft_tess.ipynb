{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GruAna/VU/blob/master/m_craft_tess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CRAFT + Tesseract"
      ],
      "metadata": {
        "id": "3hjqHsxp-sfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packages"
      ],
      "metadata": {
        "id": "QPru2sDLX4xW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "flumzrzYjxap",
        "outputId": "5da8d30b-cade-454f-a542-c916b4e9a8ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'CRAFT-pytorch' already exists and is not an empty directory.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: craft-text-detector in /usr/local/lib/python3.7/dist-packages (0.4.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from craft-text-detector) (1.4.1)\n",
            "Requirement already satisfied: opencv-python<4.5.4.62,>=3.4.8.29 in /usr/local/lib/python3.7/dist-packages (from craft-text-detector) (4.1.2.30)\n",
            "Requirement already satisfied: torchvision>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from craft-text-detector) (0.12.0+cu113)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from craft-text-detector) (1.11.0+cu113)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.7/dist-packages (from craft-text-detector) (4.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->craft-text-detector) (4.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->craft-text-detector) (4.64.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->craft-text-detector) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->craft-text-detector) (3.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->craft-text-detector) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python<4.5.4.62,>=3.4.8.29->craft-text-detector) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->craft-text-detector) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.7.0->craft-text-detector) (9.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector) (1.7.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.7/dist-packages (0.3.9)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from pytesseract) (21.3)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.7/dist-packages (from pytesseract) (9.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->pytesseract) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imgaug==0.2.6 in /usr/local/lib/python3.7/dist-packages (0.2.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.6) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.6) (1.21.6)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.6) (0.18.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.6) (1.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (1.3.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (9.2.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (2.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (2.6.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.6) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.6) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.6) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.6) (1.4.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.6) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Pillow==9.0.0\n",
            "  Using cached Pillow-9.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "Installing collected packages: Pillow\n",
            "Successfully installed Pillow-9.2.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "! sudo apt install tesseract-ocr\n",
        "! pip install craft-text-detector\n",
        "! pip install pytesseract\n",
        "! pip install imgaug==0.2.6\n",
        "! pip install --ignore-installed Pillow==9.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5lyd4_JlQPE",
        "outputId": "5657c136-2f68-436d-f32a-7c0893569c11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qsq9_mFmq4u1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "from craft_text_detector import (\n",
        "    read_image,\n",
        "    load_craftnet_model,\n",
        "    load_refinenet_model,\n",
        "    get_prediction,\n",
        "    export_detected_regions,\n",
        "    export_extra_results,\n",
        "    empty_cuda_cache\n",
        ")\n",
        "\n",
        "import pytesseract\n",
        "from pytesseract import Output\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "!cp drive/MyDrive/Colab_Notebooks/VU/utils.py .\n",
        "from utils import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "GWTwmglUZOhq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset loading"
      ],
      "metadata": {
        "id": "lhPOAy5ZYF39"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CTW1500 dataset\n",
        "\n",
        " - testing set (500 images)"
      ],
      "metadata": {
        "id": "t4ceHCnUZFEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get images. Update location of images **manually**.\n",
        "\n",
        "Comment if not using CTW1500 dataset."
      ],
      "metadata": {
        "id": "97DN9W0tPrGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# whether images are to be resized (skrinking)\n",
        "resize = False\n",
        "width = 3000\n",
        "\n",
        "# path to image directory, get full path to all files\n",
        "imgs_dir = '/content/drive/MyDrive/Colab_Notebooks/VU/CTW1500/test_images'\n",
        "\n",
        "(_, _, filenames) = next(os.walk(imgs_dir))\n",
        "filenames.sort()\n",
        "list_img_paths = [os.path.join(imgs_dir, file) for file in filenames]\n",
        "n_imgs = len(list_img_paths)\n",
        "\n",
        "# load images\n",
        "original_images = [(cv.imread(file)) for file in list_img_paths]\n",
        "                        \n",
        "# shrink images\n",
        "if resize:\n",
        "    images = shrink_all(original_images, width)\n",
        "else:\n",
        "    images = original_images.copy()\n",
        "\n",
        "# grayscale\n",
        "images = [cv.cvtColor(img, cv.COLOR_BGR2GRAY) for img in images]\n",
        "\n",
        "# # threshold\n",
        "# patches = [(img.shape[0] // 16) * 2 + 1 for img in images]\n",
        "# images = [cv.adaptiveThreshold(images[i], 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, patches[i], 5) for i in range(n_imgs)]\n",
        "# # # closing \n",
        "# kernel = cv.getStructuringElement(cv.MORPH_CROSS,(3,3))\n",
        "# images = [cv.morphologyEx(img, cv.MORPH_CLOSE, kernel) for img in images]    \n",
        "\n",
        "# Get paths to files with labels. Update location manually\n",
        "# path to label directory, get full path to all files\n",
        "labels_dir = '/content/drive/MyDrive/Colab_Notebooks/VU/CTW1500/test_labels'\n",
        "(_, _, xml_files) = next(os.walk(labels_dir))\n",
        "xml_files.sort()\n",
        "list_xml_paths = [os.path.join(labels_dir, file) for file in xml_files]\n",
        "\n",
        "# Get ground truths from all xml files\n",
        "ground_truth = []\n",
        "\n",
        "# if images where resized we need to resize also the coordinates in gt\n",
        "if resize:\n",
        "    for i, file in enumerate(list_xml_paths):\n",
        "        ratio = width / original_images[i].shape[1]\n",
        "        if ratio > 1:\n",
        "            ratio = 1\n",
        "        ground_truth.append(read_gt_ctw_test(file, scaling_ratio=ratio))\n",
        "else:\n",
        "    for i, file in enumerate(list_xml_paths):\n",
        "        ground_truth.append(read_gt_ctw_test(file))\n",
        "\n",
        "# ground_truth is in the is a list of tuples, where first is the gt word \n",
        "# and second is an array of top left and bottom right coordinates\n",
        "# format: ('text', [[tl,tl],[br,br]])"
      ],
      "metadata": {
        "id": "k8mtKHdykOfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Born digital dataset"
      ],
      "metadata": {
        "id": "L_cx090E8ODd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path to image and label directory, get full path to all files\n",
        "imgs_dir = '/content/drive/MyDrive/Colab_Notebooks/VU/BD/Challenge1_Training_Task12_Images'\n",
        "labels_dir = '/content/drive/MyDrive/Colab_Notebooks/VU/BD/ch1_training_localization_transcription_gt'\n",
        "\n",
        "(_, _, filenames) = next(os.walk(imgs_dir))\n",
        "filenames.sort()\n",
        "list_img_paths = [os.path.join(imgs_dir, file) for file in filenames]\n",
        "\n",
        "(_, _, txt_files) = next(os.walk(labels_dir))\n",
        "txt_files.sort()\n",
        "list_txt_paths = [os.path.join(labels_dir, file) for file in txt_files]\n",
        "\n",
        "n_imgs = len(list_img_paths)\n",
        "n_labels = len(list_txt_paths)\n",
        "\n",
        "assert n_imgs == n_labels, \"Check both ground truth and image files\"\n",
        "\n",
        "# whether images are to be resized (skrinking)\n",
        "resize = False\n",
        "width = 3000\n",
        "\n",
        "# load images\n",
        "original_images = [(cv.imread(file)) for file in list_img_paths]\n",
        "# load images = bmp images (detected text)\n",
        "# from already text detected images, which are provided in Kaist dataset\n",
        "# original_images = [(cv.imread(file)) for file in list_bmp_paths]\n",
        "  \n",
        "# shrink images\n",
        "if resize:\n",
        "    images = shrink_all(original_images, width)\n",
        "else:\n",
        "    images = original_images.copy()\n",
        "\n",
        "# grayscale\n",
        "images = [cv.cvtColor(img, cv.COLOR_BGR2GRAY) for img in images]\n",
        "\n",
        "# threshold\n",
        "# patches = [(img.shape[0] // 16) * 2 + 1 for img in images]\n",
        "# images = [cv.adaptiveThreshold(images[i], 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, patches[i], 5) for i in range(n_imgs)]\n",
        "\n",
        "\n",
        "# Get ground truths from all xml files\n",
        "ground_truth = []\n",
        "\n",
        "# if images where resized we need to resize also the coordinates in gt\n",
        "if resize:\n",
        "    for i, file in tqdm(enumerate(list_xml_paths)):\n",
        "        ratio = width / original_images[i].shape[1]\n",
        "        if ratio > 1:\n",
        "            ratio = 1\n",
        "        ground_truth.append(read_gt_bd(file, scaling_ratio=ratio))\n",
        "else:\n",
        "    for i, file in tqdm(enumerate(list_txt_paths)):\n",
        "        ground_truth.append(read_gt_bd(file))\n",
        "\n",
        "# ground_truth is in the is a list of tuples, where first is the gt word \n",
        "# and second is an array of top left and bottom right coordinates\n",
        "# format: ('text', [[tl,tl],[br,br]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQj2qQ5U8LJZ",
        "outputId": "77c12a79-4229-427e-d5d1-dc890a2133d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "410it [05:58,  1.14it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup for prediction"
      ],
      "metadata": {
        "id": "JzVIaQOwlyuS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6hlKfkLwJgS"
      },
      "outputs": [],
      "source": [
        "# if GPU is to be used, allow CUDA\n",
        "use_GPU = True\n",
        "\n",
        "# set and create output directory if it doesn't exist\n",
        "detected_dir = 'output'\n",
        "if not os.path.exists(detected_dir):\n",
        "    os.makedirs(detected_dir)\n",
        "\n",
        "# load models\n",
        "refine_net = load_refinenet_model(cuda=use_GPU)\n",
        "craft_net = load_craftnet_model(cuda=use_GPU)\n",
        "\n",
        "custom_config = r'--oem 3 --psm 8'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "6wEhG-RRXr5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run OCR methods - CRAFT and Tesseract"
      ],
      "metadata": {
        "id": "TmWpj-pRXz0G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbidEABzkye6",
        "outputId": "1d8051ed-b9b7-406b-e3f5-dde3f64e42cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 353/410 [08:52<01:02,  1.10s/it]"
          ]
        }
      ],
      "source": [
        "predicted = []\n",
        "\n",
        "# loop through all images in image directory\n",
        "for img in tqdm(images):\n",
        "\n",
        "    predictions = get_prediction(\n",
        "        image = img,\n",
        "        craft_net = craft_net,\n",
        "        refine_net = refine_net,\n",
        "        cuda = use_GPU,\n",
        "        poly = False\n",
        "    )\n",
        "\n",
        "    detected_regions = predictions[\"boxes\"]\n",
        "\n",
        "    image_output = []\n",
        "    for region in detected_regions:\n",
        "        coords = bounding_rectangle(region)\n",
        "        cropped = img[coords[0][1]:coords[1][1], coords[0][0]:coords[1][0]]\n",
        "        tess_output = pytesseract.image_to_data(cropped, output_type=Output.DICT, config=custom_config)['text']\n",
        "        words = [t for t in tess_output if len(t) > 0 and not t.isspace()]\n",
        "        image_output.append((\" \".join(words), coords))\n",
        "\n",
        "    predicted.append(image_output)\n",
        "\n",
        "# unload models from gpu\n",
        "if use_GPU:\n",
        "    empty_cuda_cache()\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare bounding boxes of predicition and ground truth."
      ],
      "metadata": {
        "id": "OJz4QbidZejY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count Intersection over Union (IoU) metric for bounding boxes. Store for all images in a list `iou_images`.\n",
        "\n",
        "Count Character Error Rate (CER) metric for characters in words. Store for all images in a list `cer_images`."
      ],
      "metadata": {
        "id": "hiALo69sGcaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iou_images = []\n",
        "cer_images = []\n",
        "\n",
        "# loop through images:\n",
        "for i in range(n_imgs):\n",
        "    # separate list on columns (iterate through tuples in the list)\n",
        "    if len(predicted[i]) and len(ground_truth[i]):\n",
        "        predicted_cols = list(zip(*predicted[i]))\n",
        "    else:\n",
        "        iou_images.append(None)\n",
        "        cer_images.append(None)\n",
        "        continue\n",
        "    ground_truth_cols = list(zip(*ground_truth[i]))\n",
        "\n",
        "    # take only coordinate arrays from list for each images\n",
        "    pred_boxes = predicted_cols[1]\n",
        "    gt_boxes = ground_truth_cols[1]\n",
        "    iou_from_image = iou_image(pred_boxes, gt_boxes)\n",
        "    iou_text_regions = group_text(iou_from_image)\n",
        "  \n",
        "    # take only labels for each image\n",
        "    pred_labels = predicted_cols[0]\n",
        "    gt_labels = ground_truth_cols[0]\n",
        "\n",
        "    # compare corresponding labels\n",
        "    # comparision is a list of all text regions on one image\n",
        "    comparision = []\n",
        "    for observation in iou_text_regions:\n",
        "        gt_ind = observation[-1]\n",
        "        pred_ind = observation[1]\n",
        "        predicted_text = \" \".join([pred_labels[i] for i in pred_ind])\n",
        "        gt_pred_text = (gt_labels[gt_ind], predicted_text)\n",
        "       \n",
        "\n",
        "        # comparision for one text region (on one image)\n",
        "        comparision.append((compare_text_cer(gt_pred_text, special_characters=False, case_sensitive=False, split=False)))\n",
        "\n",
        "    iou_images.append((iou_text_regions))\n",
        "    cer_images.append((comparision))"
      ],
      "metadata": {
        "id": "TzaT0gpfxwiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metrics\n",
        "Metrics for each image (average of values of all regions in one image)."
      ],
      "metadata": {
        "id": "DjHmWG0Nnhpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IoU (detection) `iou_in_image`\n",
        "\n",
        "CER (recognition) `cer_in_image`"
      ],
      "metadata": {
        "id": "Ac49TBuXnrMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iou_in_image = []\n",
        "cer_in_image = []\n",
        "\n",
        "for i in range(n_imgs):\n",
        "    # calculate mean based on results \n",
        "    if isinstance(cer_images[i], list):\n",
        "        length = len(cer_images[i])\n",
        "        mean_in_regions = average([average(list(zip(*cer_images[i][j]))[2]) for j in range(length) ])\n",
        "        iou_in_image.append(average(list(zip(*iou_images[i]))[0]))\n",
        "    else:\n",
        "        mean_in_regions = None\n",
        "        iou_in_image.append(None)\n",
        "\n",
        "    cer_in_image.append(mean_in_regions)"
      ],
      "metadata": {
        "id": "95UM74SagnjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overall results for dataset"
      ],
      "metadata": {
        "id": "pvjZ0w68pEPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specify unique filename and specification.\n",
        "\n",
        "Specification is an array of first used method, second some useful infromation."
      ],
      "metadata": {
        "id": "YtV9-vOoaYJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SELECT FROM OPTIONS BELOW OR CREATE YOUR OWN, COMMENT UNUSED:\n",
        "\n",
        "# basic tesseract (original image size, case insensitive, only alphanumeric)\n",
        "file_name = \"carfttesseract_BD_nosplit_alph\"\n",
        "specifications = [\"tesseract untrained\", \"BD, original image size, case sensitive, special char, nosplit\"]"
      ],
      "metadata": {
        "id": "qQzXmOCKL5sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8pmlQyuvK5J-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_results = pd.DataFrame(list(zip(filenames, iou_in_image, cer_in_image)), columns =['Filename', 'IoU', 'CER'])\n",
        "mean_iou = round(df_results['IoU'].mean() * 100, 1)\n",
        "mean_cer = round((1 - df_results['CER'].mean()) * 100, 1)\n",
        "\n",
        "print(file_name, \": \", specifications[-1])\n",
        "print(f\"mean IoU accuracy = {mean_iou}%, mean CER accuracy = {mean_cer}%\")\n",
        "\n",
        "df_results"
      ],
      "metadata": {
        "id": "lSn15ovCfp25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save results"
      ],
      "metadata": {
        "id": "97XUFpJ_L7Zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set and create output directory if it doesn't exist\n",
        "\n",
        "output_dir = 'results'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)"
      ],
      "metadata": {
        "id": "wdzmrNk4NR7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save to file."
      ],
      "metadata": {
        "id": "URMjcDNaaQNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create file with results (specify method and other parameters)\n",
        "\n",
        "with open('%s/result_%s.txt' % (output_dir, file_name), 'w') as output_file:\n",
        "    output_file.write(\": \".join(str(text) for text in specifications))\n",
        "    output_file.write(\"\\n\"+f\"iou = {mean_iou}\")\n",
        "    output_file.write(\"\\n\"+f\"cer = {mean_cer}\")"
      ],
      "metadata": {
        "id": "vGySn4aDaSw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize bounding rectangles and corresponing words."
      ],
      "metadata": {
        "id": "v8PoKCqAGTl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all images / one sample image\n",
        "# for i in range(n_imgs):\n",
        "i = 2\n",
        "\n",
        "im = plot_results(original_images[i], ground_truth[i], predicted[i])  \n",
        "im.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
        "\n",
        "im.savefig('%s/result_%s2.png' % (output_dir, file_name))\n",
        "im.show()\n"
      ],
      "metadata": {
        "id": "-KDYPcQGe-BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZiX6pPkK5E28"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "m_craft_tess.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO7EKbF4bNOqcsdjas3393V",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}