{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_EasyOCR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNllohFtl7HVqvCXtwjLrKO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GruAna/VU/blob/master/train_EasyOCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EasyOCR"
      ],
      "metadata": {
        "id": "8iuzqAo45UM0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packages"
      ],
      "metadata": {
        "id": "QPru2sDLX4xW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2 as cv"
      ],
      "metadata": {
        "id": "bkyZyokQ5u_o"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4OFu2Y3jrBl",
        "outputId": "41b87592-0386-46ec-f9d5-e8ec8f4a473c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Colab_Notebooks/VU/utils.py /content\n",
        "!mv /content/utils.py /content/utilities.py"
      ],
      "metadata": {
        "id": "bE9mwtlBpQRe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utilities import *"
      ],
      "metadata": {
        "id": "vAGrLMv4_JfY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "0W9WiVwRx-xi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset loading (training data)"
      ],
      "metadata": {
        "id": "lhPOAy5ZYF39"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CTW1500 dataset**"
      ],
      "metadata": {
        "id": "t4ceHCnUZFEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get images. Update location of images **manually**."
      ],
      "metadata": {
        "id": "97DN9W0tPrGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path to image directory, get full path to all files\n",
        "imgs_dir = '/content/drive/MyDrive/Colab_Notebooks/VU/FewImages/images/'\n",
        "(_, _, filenames) = next(os.walk(imgs_dir))\n",
        "filenames.sort()\n",
        "list_img_paths = [os.path.join(imgs_dir, file) for file in filenames]\n",
        "n_imgs = len(list_img_paths)"
      ],
      "metadata": {
        "id": "k8mtKHdykOfq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load images\n",
        "train_images = [(cv.imread(file)) for file in list_img_paths]"
      ],
      "metadata": {
        "id": "2nrizBXRY-Pb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get paths to files with labels. Update location **manually**."
      ],
      "metadata": {
        "id": "rLIx5BFtziDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path to label directory, get full path to all files\n",
        "labels_dir = '/content/drive/MyDrive/Colab_Notebooks/VU/FewImages/labelsxml/'\n",
        "(_, _, xml_files) = next(os.walk(labels_dir))\n",
        "xml_files.sort()\n",
        "list_xml_paths = [os.path.join(labels_dir, file) for file in xml_files]"
      ],
      "metadata": {
        "id": "KbLbqMD_Apaq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get ground truths from all xml files"
      ],
      "metadata": {
        "id": "rttWVgWP1Dg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth = []\n",
        "\n",
        "for i, file in enumerate(list_xml_paths):\n",
        "     ground_truth.append(get_labels_xml(file))\n",
        "\n",
        "# ground_truth is in the is a list of tuples, where first is the gt word \n",
        "# and second is an array of top left and bottom right coordinates\n",
        "# format: ('text', [[tl,tl],[br,br]])"
      ],
      "metadata": {
        "id": "yjB3g4kN1BeZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crop images with multiple words to one image = one word, save and create corresponding label .txt file (one for all images, called `gt.txt`)"
      ],
      "metadata": {
        "id": "zUOeZv_qx8Fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def image_text_crop(images, ground_truth, one_file='True', result_folder='./results'):\n",
        "    \"\"\"\n",
        "    Crops and saves images based on bounding box ground truth fro each text region.\n",
        "    Creates text file with corresponding annotation.\n",
        "\n",
        "    Parameter:\n",
        "    - images: loaded images\n",
        "    - groun_truth: list of gt tuples first text annotation, second np.array of \n",
        "    left top and bottom right coodinates, format: ('text', [[tl,tl],[br,br]])\n",
        "    \"\"\"\n",
        "\n",
        "    # test if there are not more gts than images\n",
        "    # else the for loop will never get to those exceeding image count\n",
        "    gt_length = len(ground_truth)\n",
        "    if len(images) > gt_length:\n",
        "        images = images[:gt_length]\n",
        "\n",
        "    if not os.path.isdir(result_folder):\n",
        "        os.mkdir(result_folder)\n",
        "    \n",
        "    all_texts = []\n",
        "    for i, img in enumerate(images):\n",
        "        name, ext = os.path.splitext(filenames[i])\n",
        "\n",
        "        # count regions in one image - used for file naming purposes\n",
        "        region = 1\n",
        "        \n",
        "        for text, bbox in ground_truth[i]:\n",
        "            # select image within coordinates (bbox)\n",
        "            cropped = img[bbox[0,1]:bbox[1,1], bbox[0,0]:bbox[1,0]]\n",
        "\n",
        "            # create image file:\n",
        "            # name in format \"original-00region.ext\"\n",
        "            new_name = name + '-' + str(region).zfill(3)\n",
        "            cv.imwrite(os.path.join(result_folder, new_name + ext), cropped)\n",
        "\n",
        "            # create  text annotation file(s)\n",
        "            if one_file:\n",
        "                all_texts.append(new_name + ext + '\\t' + text)\n",
        "            else:\n",
        "                # one file for each image with word\n",
        "                with open(os.path.join(result_folder, new_name + '.txt'), 'w') as f:\n",
        "                    f.write(text)\n",
        "            region += 1\n",
        "    \n",
        "    with open(os.path.join(result_folder, 'gt.txt'), 'w') as f:\n",
        "        for line in all_texts:\n",
        "            f.writelines(line+'\\n')\n"
      ],
      "metadata": {
        "id": "ZzyzTAwX5-Ma"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_text_crop(train_images, ground_truth)"
      ],
      "metadata": {
        "id": "DNfzqFayx9Wx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open('./results/gt.txt', 'r') as infile, open('./results/labels.csv', 'w') as outfile:\n",
        "     stripped = (line.strip() for line in infile)\n",
        "     lines = (line.split(\"\\t\") for line in stripped if line)\n",
        "     writer = csv.writer(outfile)\n",
        "     writer.writerow(['filename', 'words'])\n",
        "     writer.writerows(lines)"
      ],
      "metadata": {
        "id": "Zs21WaZ-D5J8"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp ./results/labels.csv /content/all_data/en_val\n",
        "! cp ./results/labels.csv /content/all_data/en_train_filtered"
      ],
      "metadata": {
        "id": "-JeaMjMwFeaL"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "### Training setup"
      ],
      "metadata": {
        "id": "dEpf9HQ61z4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone functions for training.\n",
        "[EasyOCR trainer](https://github.com/JaidedAI/EasyOCR/tree/master/trainer)."
      ],
      "metadata": {
        "id": "GNTdFTATv068"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/JaidedAI/EasyOCR.git "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEMKOTtBv0TZ",
        "outputId": "edec2672-4435-4030-c998-648dc7d94cba"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'EasyOCR' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "% cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eMr6TgJ6JDp",
        "outputId": "fbef4c5c-f5a6-4f0a-eb9a-e97dda981e46"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp -RT /content/EasyOCR/trainer/ /content/"
      ],
      "metadata": {
        "id": "7PEPr7yI_Qxr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train custom model. Following three cells is the content of \n",
        "[trainer.ipynb](https://github.com/JaidedAI/EasyOCR/blob/master/trainer/trainer.ipynb)."
      ],
      "metadata": {
        "id": "P8h1aITOu_92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3fhhL-q_9S8l"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.backends.cudnn as cudnn\n",
        "import yaml\n",
        "from train import train\n",
        "from utils import AttrDict\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "qRRgullnu8rR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cudnn.benchmark = True\n",
        "cudnn.deterministic = False"
      ],
      "metadata": {
        "id": "0v4VfpBDu9Z8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0Uk7qUkUuoR-"
      },
      "outputs": [],
      "source": [
        "def get_config(file_path):\n",
        "    with open(file_path, 'r', encoding=\"utf8\") as stream:\n",
        "        opt = yaml.safe_load(stream)\n",
        "    opt = AttrDict(opt)\n",
        "    if opt.lang_char == 'None':\n",
        "        characters = ''\n",
        "        for data in opt['select_data'].split('-'):\n",
        "            csv_path = os.path.join(opt['train_data'], data, 'labels.csv')\n",
        "            df = pd.read_csv(csv_path, sep='^([^,]+),', engine='python', usecols=['filename', 'words'], keep_default_na=False)\n",
        "            all_char = ''.join(df['words'])\n",
        "            characters += ''.join(set(all_char))\n",
        "        characters = sorted(set(characters))\n",
        "        opt.character= ''.join(characters)\n",
        "    else:\n",
        "        opt.character = opt.number + opt.symbol + opt.lang_char\n",
        "    os.makedirs(f'./saved_models/{opt.experiment_name}', exist_ok=True)\n",
        "    return opt\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = get_config(\"config_files/en_filtered_config.yaml\")\n",
        "train(opt, amp=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QOtRekueBiWK",
        "outputId": "4f5d9c59-1cad-4397-89a1-9b44df3cbf05"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering the images containing characters which are not in opt.character\n",
            "Filtering the images whose label is longer than opt.batch_max_length\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root: all_data\n",
            "opt.select_data: ['en_train_filtered']\n",
            "opt.batch_ratio: ['1']\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    all_data\t dataset: en_train_filtered\n",
            "all_data/en_train_filtered/.ipynb_checkpoints\n",
            "sub-directory:\t/en_train_filtered/.ipynb_checkpoints\t num samples: 178\n",
            "num total samples of en_train_filtered: 178 x 1.0 (total_data_usage_ratio) = 178\n",
            "num samples of en_train_filtered per batch: 32 x 1.0 (batch_ratio) = 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Total_batch_size: 32 = 32\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    all_data/en_val\t dataset: /\n",
            "all_data/en_val/\n",
            "sub-directory:\t/.\t num samples: 178\n",
            "--------------------------------------------------------------------------------\n",
            "No Transformation module specified\n",
            "model input parameters 64 600 20 1 256 256 97 34 None VGG BiLSTM CTC\n",
            "Model:\n",
            "DataParallel(\n",
            "  (module): Model(\n",
            "    (FeatureExtraction): VGG_FeatureExtractor(\n",
            "      (ConvNet): Sequential(\n",
            "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): ReLU(inplace=True)\n",
            "        (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (7): ReLU(inplace=True)\n",
            "        (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (9): ReLU(inplace=True)\n",
            "        (10): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
            "        (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (13): ReLU(inplace=True)\n",
            "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (16): ReLU(inplace=True)\n",
            "        (17): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
            "        (18): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (19): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
            "    (SequenceModeling): Sequential(\n",
            "      (0): BidirectionalLSTM(\n",
            "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
            "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
            "      )\n",
            "      (1): BidirectionalLSTM(\n",
            "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
            "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (Prediction): Linear(in_features=256, out_features=97, bias=True)\n",
            "  )\n",
            ")\n",
            "Modules, Parameters\n",
            "module.FeatureExtraction.ConvNet.0.weight 288\n",
            "module.FeatureExtraction.ConvNet.0.bias 32\n",
            "module.FeatureExtraction.ConvNet.3.weight 18432\n",
            "module.FeatureExtraction.ConvNet.3.bias 64\n",
            "module.FeatureExtraction.ConvNet.6.weight 73728\n",
            "module.FeatureExtraction.ConvNet.6.bias 128\n",
            "module.FeatureExtraction.ConvNet.8.weight 147456\n",
            "module.FeatureExtraction.ConvNet.8.bias 128\n",
            "module.FeatureExtraction.ConvNet.11.weight 294912\n",
            "module.FeatureExtraction.ConvNet.12.weight 256\n",
            "module.FeatureExtraction.ConvNet.12.bias 256\n",
            "module.FeatureExtraction.ConvNet.14.weight 589824\n",
            "module.FeatureExtraction.ConvNet.15.weight 256\n",
            "module.FeatureExtraction.ConvNet.15.bias 256\n",
            "module.FeatureExtraction.ConvNet.18.weight 262144\n",
            "module.FeatureExtraction.ConvNet.18.bias 256\n",
            "module.SequenceModeling.0.rnn.weight_ih_l0 262144\n",
            "module.SequenceModeling.0.rnn.weight_hh_l0 262144\n",
            "module.SequenceModeling.0.rnn.bias_ih_l0 1024\n",
            "module.SequenceModeling.0.rnn.bias_hh_l0 1024\n",
            "module.SequenceModeling.0.rnn.weight_ih_l0_reverse 262144\n",
            "module.SequenceModeling.0.rnn.weight_hh_l0_reverse 262144\n",
            "module.SequenceModeling.0.rnn.bias_ih_l0_reverse 1024\n",
            "module.SequenceModeling.0.rnn.bias_hh_l0_reverse 1024\n",
            "module.SequenceModeling.0.linear.weight 131072\n",
            "module.SequenceModeling.0.linear.bias 256\n",
            "module.SequenceModeling.1.rnn.weight_ih_l0 262144\n",
            "module.SequenceModeling.1.rnn.weight_hh_l0 262144\n",
            "module.SequenceModeling.1.rnn.bias_ih_l0 1024\n",
            "module.SequenceModeling.1.rnn.bias_hh_l0 1024\n",
            "module.SequenceModeling.1.rnn.weight_ih_l0_reverse 262144\n",
            "module.SequenceModeling.1.rnn.weight_hh_l0_reverse 262144\n",
            "module.SequenceModeling.1.rnn.bias_ih_l0_reverse 1024\n",
            "module.SequenceModeling.1.rnn.bias_hh_l0_reverse 1024\n",
            "module.SequenceModeling.1.linear.weight 131072\n",
            "module.SequenceModeling.1.linear.bias 256\n",
            "module.Prediction.weight 24832\n",
            "module.Prediction.bias 97\n",
            "Total Trainable Params: 3781345\n",
            "Trainable params num :  3781345\n",
            "Optimizer:\n",
            "Adadelta (\n",
            "Parameter Group 0\n",
            "    eps: 1e-08\n",
            "    lr: 1.0\n",
            "    rho: 0.95\n",
            "    weight_decay: 0\n",
            ")\n",
            "------------ Options -------------\n",
            "number: 0123456789\n",
            "symbol: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ €\n",
            "lang_char: ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "experiment_name: en_filtered\n",
            "train_data: all_data\n",
            "valid_data: all_data/en_val\n",
            "manualSeed: 1111\n",
            "workers: 6\n",
            "batch_size: 32\n",
            "num_iter: 300000\n",
            "valInterval: 20000\n",
            "saved_model: \n",
            "FT: False\n",
            "optim: False\n",
            "lr: 1.0\n",
            "beta1: 0.9\n",
            "rho: 0.95\n",
            "eps: 1e-08\n",
            "grad_clip: 5\n",
            "select_data: ['en_train_filtered']\n",
            "batch_ratio: ['1']\n",
            "total_data_usage_ratio: 1.0\n",
            "batch_max_length: 34\n",
            "imgH: 64\n",
            "imgW: 600\n",
            "rgb: False\n",
            "contrast_adjust: 0.0\n",
            "sensitive: True\n",
            "PAD: True\n",
            "data_filtering_off: False\n",
            "Transformation: None\n",
            "FeatureExtraction: VGG\n",
            "SequenceModeling: BiLSTM\n",
            "Prediction: CTC\n",
            "num_fiducial: 20\n",
            "input_channel: 1\n",
            "output_channel: 256\n",
            "hidden_size: 256\n",
            "decode: greedy\n",
            "new_prediction: False\n",
            "freeze_FeatureFxtraction: False\n",
            "freeze_SequenceModeling: False\n",
            "character: 0123456789!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ €ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "num_class: 97\n",
            "---------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-6d4c06a1ca45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"config_files/en_filtered_config.yaml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(opt, show_number, amp)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mimage_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_max_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/dataset.py\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader_iter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader_iter_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0mbalanced_batch_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mbalanced_batch_texts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1222\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\", line 471, in __getitem__\n    return self.dataset[self.indices[idx]]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\", line 416, in __getitem__\n    return self.datasets[dataset_idx][sample_idx]\n  File \"/content/dataset.py\", line 181, in __getitem__\n    img = Image.open(img_fpath).convert('L')\n  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 2843, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: 'all_data/en_train_filtered/.ipynb_checkpoints/0020-009.jpg'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp ./results/labels.csv /content/all_data/en_train_filtered/.ipynb_checkpoints"
      ],
      "metadata": {
        "id": "hAHz7AqQF-se"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -a all_data/en_train_filtered/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMxEjODKFFyC",
        "outputId": "a26e13a0-a86b-406e-af9a-b77461bd6a2d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\t      0006-002.jpg  0009-008.jpg  0012-012.jpg\t0018-010.jpg\n",
            "..\t      0006-003.jpg  0009-009.jpg  0012-013.jpg\t0018-011.jpg\n",
            "0001-001.jpg  0007-001.jpg  0009-010.jpg  0012-014.jpg\t0018-012.jpg\n",
            "0001-002.jpg  0007-002.jpg  0010-001.jpg  0012-015.jpg\t0018-013.jpg\n",
            "0001-003.jpg  0007-003.jpg  0010-002.jpg  0012-016.jpg\t0018-014.jpg\n",
            "0001-004.jpg  0007-004.jpg  0010-003.jpg  0012-017.jpg\t0018-015.jpg\n",
            "0001-005.jpg  0007-005.jpg  0010-004.jpg  0012-018.jpg\t0018-016.jpg\n",
            "0001-006.jpg  0007-006.jpg  0010-005.jpg  0012-019.jpg\t0018-017.jpg\n",
            "0001-007.jpg  0007-007.jpg  0010-006.jpg  0012-020.jpg\t0018-018.jpg\n",
            "0002-001.jpg  0007-008.jpg  0010-007.jpg  0012-021.jpg\t0019-001.jpg\n",
            "0002-002.jpg  0007-009.jpg  0010-008.jpg  0012-022.jpg\t0019-002.jpg\n",
            "0002-003.jpg  0007-010.jpg  0010-009.jpg  0012-023.jpg\t0019-003.jpg\n",
            "0002-004.jpg  0007-011.jpg  0010-010.jpg  0012-024.jpg\t0019-004.jpg\n",
            "0003-001.jpg  0007-012.jpg  0010-011.jpg  0012-025.jpg\t0019-005.jpg\n",
            "0003-002.jpg  0007-013.jpg  0011-001.jpg  0012-026.jpg\t0020-001.jpg\n",
            "0003-003.jpg  0007-014.jpg  0011-002.jpg  0013-001.jpg\t0020-002.jpg\n",
            "0003-004.jpg  0007-015.jpg  0011-003.jpg  0013-002.jpg\t0020-003.jpg\n",
            "0003-005.jpg  0008-001.jpg  0011-004.jpg  0013-003.jpg\t0020-004.jpg\n",
            "0003-006.jpg  0008-002.jpg  0011-005.jpg  0014-001.jpg\t0020-005.jpg\n",
            "0003-007.jpg  0008-003.jpg  0011-006.jpg  0014-002.jpg\t0020-006.jpg\n",
            "0004-001.jpg  0008-004.jpg  0011-007.jpg  0015-001.jpg\t0020-007.jpg\n",
            "0004-002.jpg  0008-005.jpg  0011-008.jpg  0015-002.jpg\t0020-008.jpg\n",
            "0004-003.jpg  0008-006.jpg  0011-009.jpg  0015-003.jpg\t0020-009.jpg\n",
            "0004-004.jpg  0008-007.jpg  0011-010.jpg  0015-004.jpg\t0020-010.jpg\n",
            "0004-005.jpg  0008-008.jpg  0011-011.jpg  0015-005.jpg\t0020-011.jpg\n",
            "0004-006.jpg  0008-009.jpg  0011-012.jpg  0016-001.jpg\t0020-012.jpg\n",
            "0004-007.jpg  0008-010.jpg  0011-013.jpg  0016-002.jpg\t0020-013.jpg\n",
            "0004-008.jpg  0008-011.jpg  0011-014.jpg  0016-003.jpg\t0020-014.jpg\n",
            "0004-009.jpg  0008-012.jpg  0011-015.jpg  0017-001.jpg\t0020-015.jpg\n",
            "0004-010.jpg  0008-013.jpg  0012-001.jpg  0017-002.jpg\t0020-016.jpg\n",
            "0004-011.jpg  0008-014.jpg  0012-002.jpg  0017-003.jpg\t0020-017.jpg\n",
            "0004-012.jpg  0008-015.jpg  0012-003.jpg  0018-001.jpg\t0020-018.jpg\n",
            "0004-013.jpg  0008-016.jpg  0012-004.jpg  0018-002.jpg\t0020-019.jpg\n",
            "0004-014.jpg  0009-001.jpg  0012-005.jpg  0018-003.jpg\tgt.txt\n",
            "0005-001.jpg  0009-002.jpg  0012-006.jpg  0018-004.jpg\t.ipynb_checkpoints\n",
            "0005-002.jpg  0009-003.jpg  0012-007.jpg  0018-005.jpg\tlabels.csv\n",
            "0005-003.jpg  0009-004.jpg  0012-008.jpg  0018-006.jpg\n",
            "0005-004.jpg  0009-005.jpg  0012-009.jpg  0018-007.jpg\n",
            "0005-005.jpg  0009-006.jpg  0012-010.jpg  0018-008.jpg\n",
            "0006-001.jpg  0009-007.jpg  0012-011.jpg  0018-009.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Move training images to directory `/content/EasyOCR/trainer/all_data`"
      ],
      "metadata": {
        "id": "51vH-hoM1xYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "% mkdir ./all_data/en_train_filtered"
      ],
      "metadata": {
        "id": "yUUMbtSc7Wu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "% mkdir ./all_data/en_val"
      ],
      "metadata": {
        "id": "r4CPMma071eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "% cp -RT /content/results/ /content/EasyOCR/trainer/all_data/en_train_filtered/"
      ],
      "metadata": {
        "id": "2_gEbnPk1wRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "% cp -RT ./all_data/en_train_filtered/ ./all_data/en_val"
      ],
      "metadata": {
        "id": "bkgApd8d7qUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = get_config(\"/content/EasyOCR/trainer/config_files/en_filtered_config.yaml\")\n",
        "train(opt, amp=False)"
      ],
      "metadata": {
        "id": "B1Tcu6pF8E3x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}