{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "m_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMtiUksk+ecGAsBa94p9US",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GruAna/VU/blob/master/m_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras-OCR"
      ],
      "metadata": {
        "id": "fayjhoskX87v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packages"
      ],
      "metadata": {
        "id": "QPru2sDLX4xW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These two versions of keras-ocr and matplotlib works together on Google Colab"
      ],
      "metadata": {
        "id": "wvR0uPbhabiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-ocr==0.8.9\n",
        "!pip install matplotlib==3.3.0\n",
        "!pip install imgaug==0.2.6      # because of incompatibility warning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Jo_k8VY0Q1s",
        "outputId": "1ebad4ec-ee77-4f5f-f474-b4b5e06ef9c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-ocr==0.8.9 in /usr/local/lib/python3.7/dist-packages (0.8.9)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.7/dist-packages (from keras-ocr==0.8.9) (1.3.0.post2)\n",
            "Requirement already satisfied: efficientnet==1.0.0 in /usr/local/lib/python3.7/dist-packages (from keras-ocr==0.8.9) (1.0.0)\n",
            "Requirement already satisfied: fonttools in /usr/local/lib/python3.7/dist-packages (from keras-ocr==0.8.9) (4.33.3)\n",
            "Requirement already satisfied: validators in /usr/local/lib/python3.7/dist-packages (from keras-ocr==0.8.9) (0.19.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-ocr==0.8.9) (4.64.0)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from keras-ocr==0.8.9) (0.5.3)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.7/dist-packages (from keras-ocr==0.8.9) (1.8.2)\n",
            "Requirement already satisfied: essential_generators in /usr/local/lib/python3.7/dist-packages (from keras-ocr==0.8.9) (1.0)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (from keras-ocr==0.8.9) (0.2.6)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->keras-ocr==0.8.9) (1.0.8)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->keras-ocr==0.8.9) (0.18.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0->keras-ocr==0.8.9) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0->keras-ocr==0.8.9) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0->keras-ocr==0.8.9) (1.5.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug->keras-ocr==0.8.9) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug->keras-ocr==0.8.9) (1.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr==0.8.9) (3.3.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr==0.8.9) (1.3.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr==0.8.9) (7.1.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr==0.8.9) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr==0.8.9) (2021.11.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr==0.8.9) (2.4.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->keras-ocr==0.8.9) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->keras-ocr==0.8.9) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->keras-ocr==0.8.9) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->keras-ocr==0.8.9) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->keras-ocr==0.8.9) (4.2.0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->keras-ocr==0.8.9) (4.4.2)\n",
            "Requirement already satisfied: matplotlib==3.3.0 in /usr/local/lib/python3.7/dist-packages (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.0) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.0) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.0) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.0) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.3.0) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.3.0) (1.15.0)\n",
            "Requirement already satisfied: imgaug==0.2.6 in /usr/local/lib/python3.7/dist-packages (0.2.6)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.6) (0.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.6) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.6) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.6) (1.21.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (2021.11.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (3.3.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (2.6.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (2.4.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (7.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.6) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.6) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.6) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.6) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.6) (4.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount google drive.\n"
      ],
      "metadata": {
        "id": "WdINgqa1QFI6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C9fJv6vF7cz",
        "outputId": "988fac32-f624-4826-a0e1-b9b36a6945f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2 as cv\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import keras_ocr"
      ],
      "metadata": {
        "id": "DIe3a5KNaneG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/Colab_Notebooks/VU/utils.py .\n",
        "from utils import *"
      ],
      "metadata": {
        "id": "-22w7Sew_hJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "2WQ-zxFAa8bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# whether images are to be resized (skrinking)\n",
        "\n",
        "resize = False\n",
        "width = 300"
      ],
      "metadata": {
        "id": "Dmirpm9v4sk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset loading"
      ],
      "metadata": {
        "id": "lhPOAy5ZYF39"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CTW1500 dataset**"
      ],
      "metadata": {
        "id": "t4ceHCnUZFEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get images. Update location of images **manually**."
      ],
      "metadata": {
        "id": "_QDhvWQ5bffz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path to image directory, get full path to all files\n",
        "imgs_dir = '/content/drive/MyDrive/Colab_Notebooks/VU/FewImages/images/'\n",
        "(_, _, filenames) = next(os.walk(imgs_dir))\n",
        "filenames.sort()\n",
        "list_img_paths = [os.path.join(imgs_dir, file) for file in filenames]\n",
        "n_imgs = len(list_img_paths)"
      ],
      "metadata": {
        "id": "k8mtKHdykOfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load images\n",
        "original_images = [(cv.imread(file)) for file in list_img_paths]\n",
        "                        \n",
        "# shrink images\n",
        "if resize:\n",
        "    images = shrink_all(original_images, width)\n",
        "else:\n",
        "    images = original_images.copy()"
      ],
      "metadata": {
        "id": "2nrizBXRY-Pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get paths to files with labels. Update location **manually**."
      ],
      "metadata": {
        "id": "rLIx5BFtziDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_dir = '/content/drive/MyDrive/Colab_Notebooks/VU/FewImages/labelsxml/'\n",
        "(_, _, xml_files) = next(os.walk(labels_dir))\n",
        "xml_files.sort()\n",
        "list_xml_paths = [os.path.join(labels_dir, file) for file in xml_files]"
      ],
      "metadata": {
        "id": "e5ip8BIWbff0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get ground truths from all xml files"
      ],
      "metadata": {
        "id": "_QwYyQMUbff0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "ground_truth = []\n",
        "\n",
        "# if images where resized we need to resize also the coordinates in gt\n",
        "if resize:\n",
        "    for i, file in enumerate(list_xml_paths):\n",
        "        ratio = width / original_images[i].shape[1]\n",
        "        if ratio > 1:\n",
        "            ratio = 1\n",
        "        ground_truth.append(get_labels_xml(file, scaling_ratio=ratio))\n",
        "else:\n",
        "    for i, file in enumerate(list_xml_paths):\n",
        "        ground_truth.append(get_labels_xml(file))\n",
        "\n",
        "# ground_truth is in the is a list of tuples, where first is the gt word \n",
        "# and second is an array of top left and bottom right coordinates"
      ],
      "metadata": {
        "id": "94QkEv47bff1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "6wEhG-RRXr5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run OCR method."
      ],
      "metadata": {
        "id": "TmWpj-pRXz0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# keras-ocr will automatically download pretrained weights for the detector and recognizer.\n",
        "pipeline = keras_ocr.pipeline.Pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo8yVymEudy0",
        "outputId": "75f1a92a-2468-4265-d816-bce254ae3519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for /root/.keras-ocr/craft_mlt_25k.h5\n",
            "Downloading /root/.keras-ocr/craft_mlt_25k.h5\n",
            "Looking for /root/.keras-ocr/crnn_kurapan.h5\n",
            "Downloading /root/.keras-ocr/crnn_kurapan.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adjust batch size based on your GPU."
      ],
      "metadata": {
        "id": "RwUv4hPGfiwQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "gm_O-pmdz167",
        "outputId": "47a05cf9-973e-4235-b824-ecbb1e1bfb9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-910ad9e255a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnumber_of_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m# else is for last, possibly incomplete, batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_ocr/pipeline.py\u001b[0m in \u001b[0;36mrecognize\u001b[0;34m(self, images, detection_kwargs, recognition_kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecognition_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mrecognition_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mbox_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdetection_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         prediction_groups = self.recognizer.recognize_from_boxes(\n\u001b[1;32m     64\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbox_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mrecognition_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_ocr/detection.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, images, detection_threshold, text_threshold, link_threshold, size_threshold, **kwargs)\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0msize_threshold\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mminimum\u001b[0m \u001b[0marea\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m         \"\"\"\n\u001b[0;32m--> 778\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompute_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         boxes = getBoxes(\n\u001b[1;32m    780\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_ocr/detection.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0msize_threshold\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mminimum\u001b[0m \u001b[0marea\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m         \"\"\"\n\u001b[0;32m--> 778\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompute_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         boxes = getBoxes(\n\u001b[1;32m    780\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_ocr/detection.py\u001b[0m in \u001b[0;36mcompute_input\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.229\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.225\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mvariance\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1098,738) (3,) (1098,738) "
          ]
        }
      ],
      "source": [
        "predictions = []\n",
        "\n",
        "# adjust batch size (step)\n",
        "# step = 1 # for large images (at least one has one dimension greater than 800px)\n",
        "step = 1                                 # batch size\n",
        "number_of_batches = n_imgs // step   # how many times does a batch of given step size fits to list_img_paths (based on length) (integer division)\n",
        "for i in tqdm(range(number_of_batches)):\n",
        "    if (i+1)*step+1 < step*number_of_batches:\n",
        "        predictions += (pipeline.recognize(images[i*step : (i+1)*step]))\n",
        "    # else is for last, possibly incomplete, batch\n",
        "    else:\n",
        "        predictions += (pipeline.recognize(images[i*step : ]))\n",
        "    # each list of predictions in prediction_groups is a list of (word, box) tuples.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Plot the predictions\n",
        "# fig, axs = plt.subplots(nrows=len(images), figsize=(200, 200))\n",
        "# for ax, image, predicts in zip(axs, images, predictions):\n",
        "#     keras_ocr.tools.drawAnnotations(image=image, predictions=predicts, ax=ax)"
      ],
      "metadata": {
        "id": "Ph6aKnaJq1e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results postprocessing"
      ],
      "metadata": {
        "id": "p3KvsVMUZVs9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate bounding rectangles for detected words in an image.\n",
        "\n",
        "For all images.\n",
        "\n",
        "Replace polygon coordinates by these two rectangle coordinates."
      ],
      "metadata": {
        "id": "Q2CsgcQJZXfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# gather non empty predictions in a list of tuples (word, bounding_box_coordinates)\n",
        "# predicted contains all images, each image can have multiple recognized words\n",
        "# each image contains tuples in mentioned format\n",
        "\n",
        "predicted = []\n",
        "for i in range(n_imgs):\n",
        "    results = []\n",
        "    for text, box in predictions[i]:\n",
        "        if len(text) > 0 and not text.isspace():\n",
        "            results.append((text, bounding_rectangle(box)))\n",
        "    predicted.append(results)"
      ],
      "metadata": {
        "id": "OirNcOor1qc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare bounding boxes of predicition and ground truth."
      ],
      "metadata": {
        "id": "OJz4QbidZejY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count Intersection over Union (IoU) metric for bounding boxes. Store for all images in a list `iou_images`.\n",
        "\n",
        "Count Character Error Rate (CER) metric for characters in words. Store for all images in a list `cer_images`."
      ],
      "metadata": {
        "id": "hiALo69sGcaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iou_images = []\n",
        "cer_images = []\n",
        "\n",
        "# loop through images:\n",
        "for i in range(n_imgs)):\n",
        "    # separate list on columns (iterate through tuples in the list)\n",
        "    predicted_cols = list(zip(*predicted[i]))\n",
        "    ground_truth_cols = list(zip(*ground_truth[i]))\n",
        "    # take only coordinate arrays from list for each images\n",
        "    pred_boxes = predicted_cols[1]\n",
        "    gt_boxes = ground_truth_cols[1]\n",
        "    iou_from_image = iou_image(pred_boxes, gt_boxes)\n",
        "\n",
        "    iou_text_regions = group_text(iou_from_image)\n",
        "\n",
        "    # take only labels for each image\n",
        "    pred_labels = predicted_cols[0]\n",
        "    gt_labels = ground_truth_cols[0]\n",
        "\n",
        "    # compare corresponding labels\n",
        "    # comparision is a list of all text regions on one image\n",
        "    comparision = []\n",
        "    for gt_ind, observation in enumerate(iou_text_regions):\n",
        "        pred_ind = observation[1]\n",
        "        predicted_text = \" \".join([pred_labels[i] for i in pred_ind])\n",
        "        gt_pred_text = (gt_labels[gt_ind], predicted_text)\n",
        "        \n",
        "        # comparision for one text region (on one image)\n",
        "        comparision.append((compare_text_cer(gt_pred_text)))\n",
        "\n",
        "    iou_images.append((iou_text_regions))\n",
        "    cer_images.append((comparision))"
      ],
      "metadata": {
        "id": "tAU6BR-ebTk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metrics\n",
        "Metrics for each image (average of values of all regions in one image)."
      ],
      "metadata": {
        "id": "ZW6TbyvLcZsm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IoU (detection) `iou_in_image`\n",
        "\n",
        "CER (recognition) `cer_in_image`"
      ],
      "metadata": {
        "id": "Ac49TBuXnrMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iou_in_image = []\n",
        "cer_in_image = []\n",
        "\n",
        "for i in range(n_imgs):\n",
        "    mean_in_regions = [average(list(zip(*cer_images[i][j]))[2]) for j in range(len(cer_images[i]))]\n",
        "    cer_in_image.append(average(mean_in_regions))\n",
        "    iou_in_image.append(average(list(zip(*iou_images[i]))[0]))"
      ],
      "metadata": {
        "id": "95UM74SagnjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overall results for dataset"
      ],
      "metadata": {
        "id": "pvjZ0w68pEPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_results = pd.DataFrame(list(zip(filenames, iou_in_image, cer_in_image)), columns =['Filename', 'IoU', 'CER'])\n",
        "mean_iou = round(df_results['IoU'].mean() * 100, 1)\n",
        "mean_cer = round((1 - df_results['CER'].mean()) * 100, 1)\n",
        "print(f\"mean IoU accuracy = {mean_iou}%, mean CER accuracy = {mean_cer}%\")\n",
        "\n",
        "df_results"
      ],
      "metadata": {
        "id": "lSn15ovCfp25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save results"
      ],
      "metadata": {
        "id": "97XUFpJ_L7Zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set and create output directory if it doesn't exist\n",
        "\n",
        "output_dir = 'results'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)"
      ],
      "metadata": {
        "id": "wdzmrNk4NR7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specify unique filename and specification.\n",
        "\n",
        "Specification is an array of first used method, second some useful infromation."
      ],
      "metadata": {
        "id": "YtV9-vOoaYJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SELECT FROM OR CREATE OWN, COMMENT UNUSED:\n",
        "\n",
        "# basic keras-OCR (original image size, case insensitive, only alphanumeric)\n",
        "file_name = \"kerasOCR_basic\"\n",
        "specifications = [\"keras-OCR\", \"original image width, case insensitive, only alphanumeric\"]\n",
        "\n",
        "# basic keras-OCR (300px image width, case insensitive, only alphanumeric)\n",
        "# file_name = \"kerasOcr_smallimgs\"\n",
        "# specifications = [\"keras-OCR\", \"300px image width, case insensitive, only alphanumeric\"]"
      ],
      "metadata": {
        "id": "qQzXmOCKL5sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create file with results (specify method and other parameters)\n",
        "\n",
        "with open('%s/result_%s.txt' % (output_dir, file_name), 'w') as output_file:\n",
        "    output_file.write(\": \".join(str(text) for text in specifications))\n",
        "    output_file.write(\"\\n\"+f\"iou = {mean_iou}\")\n",
        "    output_file.write(\"\\n\"+f\"cer = {mean_cer}\")"
      ],
      "metadata": {
        "id": "vGySn4aDaSw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize bounding rectangles and corresponing words."
      ],
      "metadata": {
        "id": "v8PoKCqAGTl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all images / one sample image\n",
        "# for i in range(len(images)):\n",
        "i = 0\n",
        "\n",
        "im = plot_results(images[i], ground_truth[i], predicted[i])  \n",
        "im.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
        "\n",
        "im.savefig('%s/result_%s.png' % (output_dir, file_name))\n",
        "im.show()\n"
      ],
      "metadata": {
        "id": "-KDYPcQGe-BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TBz5sKhCe5s5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}